{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2u0bSmPhow9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DNyGHEovrC2N"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Urvashi\\Desktop\\New folder\\Urvashi\\Datasets\\Amazon_Unlocked_Mobile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1276,
     "status": "ok",
     "timestamp": 1535478923733,
     "user": {
      "displayName": "Smartprep",
      "photoUrl": "//lh3.googleusercontent.com/-AxJUbILQqDc/AAAAAAAAAAI/AAAAAAAAHMI/PQ1nq0mgUdk/s50-c-k-no/photo.jpg",
      "userId": "114643924031589572260"
     },
     "user_tz": -330
    },
    "id": "dkieiidKrOYP",
    "outputId": "ea69624b-a190-4a42-d84a-e972e2f21424"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0  \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0  \n",
       "2       5                                       Very pleased           0.0  \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0  \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzLKkoaErPyR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 413840 entries, 0 to 413839\n",
      "Data columns (total 6 columns):\n",
      "Product Name    413840 non-null object\n",
      "Brand Name      348669 non-null object\n",
      "Price           407907 non-null float64\n",
      "Rating          413840 non-null int64\n",
      "Reviews         413778 non-null object\n",
      "Review Votes    401544 non-null float64\n",
      "dtypes: float64(2), int64(1), object(3)\n",
      "memory usage: 18.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product Name        0\n",
       "Brand Name      65171\n",
       "Price            5933\n",
       "Rating              0\n",
       "Reviews            62\n",
       "Review Votes    12296\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    223605\n",
       "1     72350\n",
       "4     61392\n",
       "3     31765\n",
       "2     24728\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Positively Rated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>I feel so LUCKY to have found this used (phone...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>nice phone, nice up grade from my pantach revu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Very pleased</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>It works good but it goes slow sometimes but i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>199.99</td>\n",
       "      <td>4</td>\n",
       "      <td>Great phone to replace my lost phone. The only...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product Name Brand Name   Price  \\\n",
       "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
       "\n",
       "   Rating                                            Reviews  Review Votes  \\\n",
       "0       5  I feel so LUCKY to have found this used (phone...           1.0   \n",
       "1       4  nice phone, nice up grade from my pantach revu...           0.0   \n",
       "2       5                                       Very pleased           0.0   \n",
       "3       4  It works good but it goes slow sometimes but i...           0.0   \n",
       "4       4  Great phone to replace my lost phone. The only...           0.0   \n",
       "\n",
       "   Positively Rated  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Cleaning : Drop the rows with null values\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "df = df[df[\"Rating\"] !=3] # drop the data where Rating ==3\n",
    "\n",
    "# create a new column 'Positively rated' where, if rating is more than 3, we put 1 else 0\n",
    "\n",
    "df[\"Positively Rated\"] = np.where(df[\"Rating\"] > 3,1,0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : We will consider only \"Reviews\" and \"Positively Rated\" columns for our analysis, where \"Reviews\" is X variable and \"Positively Rated\" is y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7482686025879323"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Positively Rated\"].mean()\n",
    "\n",
    "# our data is skewed to Positive Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231207,)\n",
      "(231207,)\n",
      "(77070,)\n",
      "(77070,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(df[\"Reviews\"],df[\"Positively Rated\"],random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train first entry \n",
      " I feel so LUCKY to have found this used (phone to us & not used hard at all), phone on line from someone who upgraded and sold this one. My Son liked his old one that finally fell apart after 2.5+ years and didn't want an upgrade!! Thank you Seller, we really appreciate it & your honesty re: said used phone.I recommend this seller very highly & would but from them again!!\n"
     ]
    }
   ],
   "source": [
    "print(\"X train first entry \\n {}\".format(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '00000', '000000', '0000000', '0000from', '0001', '0004', '000ma', '000mah', '000mh', '000restricted', '001', '002', '0051', '006', '007', '00am', '00bucks', '00emotional', '00for', '00it', '00k', '00now', '00pm', '00so', '00time', '00us', '01', '01008', '011', '012', '013287002557427', '013435003182980', '014', '0155379', '016', '016g', '016s', '018633051660f', '019s', '02', '02may13', '02mbps', '03', '032g', '032port', '0330', '03pm', '04', '0400', '0412', '04pm', '04th', '05', '050', '0500tkx', '050mms', '050prot', '051', '056', '0572013', '05th', '05the', '05using', '06', '061', '062', '0630', '066', '06pm', '07', '0700', '07am', '07nov2015', '08', '0804245', '0808', '0825', '0829', '087', '087581287', '08in', '08mms', '08this', '09', '0909853', '09on', '0_1439_7', '0_1507_7', '0_print_120716', '0_user_manual', '0a', '0also', '0an', '0b3tbzlidhq7dce1bv05qdefaota', '0bj7255rf1f1a1118w65', '0c', '0cant']\n"
     ]
    }
   ],
   "source": [
    "# use CountVectorizer to fit and then transform the text into Bag of words. Note, we can directly use fit_transform method or we\n",
    "# can first fit and then transform\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect = vect.fit(X_train)\n",
    "\n",
    "print(vect.get_feature_names()[:100]) #get_feature_names is a method of seeing the words which have been created from training_set\n",
    "\n",
    "X_train_vect = vect.transform(X_train)  # after fitting, we transform the X_train to CountVectorized object having vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the vocabulary which we have generated from CountVectorizer is quite messy. It has lots of misspelled words and words having numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231207, 53216)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vect.shape)\n",
    "\n",
    "# so for each 231207 vectors, we have a vector of 53216 length having count of words. NOte : any words that didnt appear in\n",
    "# X_train, but appeared in X_test will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score from f1 score 0.9675558387435637\n",
      "Score from roc_auc 0.9268686014350423\n"
     ]
    }
   ],
   "source": [
    "# fit a Logistic Regression the model and check its performance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train_vect,y_train)\n",
    "X_test_vect = vect.transform(X_test)\n",
    "predictions = log_reg.predict(X_test_vect)\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "score_f1 = f1_score(y_test,predictions,average=\"binary\")\n",
    "score_roc_auc = roc_auc_score(y_test,predictions)\n",
    "\n",
    "print(\"Score from f1 score {}\".format(score_f1))\n",
    "print(\"Score from roc_auc {}\".format(score_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note : there are 2 things one is tfidfTransformer : which will transform the Countvectorizer object\n",
    "# 2nd is TfidfVectorizer which takes X_train directly and then automatically Vectorizers and changes it to tfidf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train after transformation is (231207, 53216)\n",
      "Score from f1 score 0.9663790795484968\n",
      "Score from roc_auc 0.9276650766291203\n"
     ]
    }
   ],
   "source": [
    "# Improving the model with tfigfTransformer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_vect)   # note : this takes countVectorizer object\n",
    "print(\"Shape of X_train after transformation is {}\".format(X_train_tfidf.shape))\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train_tfidf,y_train)\n",
    "X_test_vect = vect.transform(X_test)\n",
    "X_test_tfidf = tfidf.transform(X_test_vect)\n",
    "predictions = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "score_f1 = f1_score(y_test,predictions,average=\"binary\")\n",
    "score_roc_auc = roc_auc_score(y_test,predictions)\n",
    "\n",
    "print(\"Score from f1 score {}\".format(score_f1))\n",
    "print(\"Score from roc_auc {}\".format(score_roc_auc))\n",
    "\n",
    "# so we can see after using tfidf, our model's performance has improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train after transformation is (231207, 53216)\n",
      "Score from f1 score 0.9551256095628752\n",
      "Score from roc_auc 0.9255079702302214\n"
     ]
    }
   ],
   "source": [
    "# Improving the model with tfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) \n",
    "print(\"Shape of X_train after transformation is {}\".format(X_train_tfidf.shape))\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train_tfidf,y_train)\n",
    "X_test_tfidf = vect.transform(X_test)\n",
    "predictions = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "score_f1 = f1_score(y_test,predictions,average=\"binary\")\n",
    "score_roc_auc = roc_auc_score(y_test,predictions)\n",
    "\n",
    "print(\"Score from f1 score {}\".format(score_f1))\n",
    "print(\"Score from roc_auc {}\".format(score_roc_auc))\n",
    "\n",
    "# so we can see after using tfidf, our model's performance has improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train after transformation is (231207, 17951)\n",
      "Score from f1 score 0.9658710145428168\n",
      "Score from roc_auc 0.9266100666746837\n"
     ]
    }
   ],
   "source": [
    "# We can specify the features which we want to choose having some minimum documents. This can be done both in the CountVectorizer\n",
    "# and tfidf.Suppose we want to choose only those words, that have occured at least 5 times in each sentence etc.\n",
    "\n",
    "# also, we can tell it to remove stopwords\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5,stop_words=\"english\")\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)   # note : this takes countVectorizer object\n",
    "print(\"Shape of X_train after transformation is {}\".format(X_train_tfidf.shape))\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train_tfidf,y_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "predictions = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "score_f1 = f1_score(y_test,predictions,average=\"binary\")\n",
    "score_roc_auc = roc_auc_score(y_test,predictions)\n",
    "\n",
    "print(\"Score from f1 score {}\".format(score_f1))\n",
    "print(\"Score from roc_auc {}\".format(score_roc_auc))\n",
    "\n",
    "# so we can see after using tfidf, our model's performance has improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our features have decreaed from 53216 to 17951 by using min_df=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to see the feature_names, then fit the X_train first and the created object will have feature names. If you are \n",
    "# using fit_transform directly, then it is not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train after transformation is (231207, 17649)\n",
      "Score from f1 score 0.9611076647366971\n",
      "Score from roc_auc 0.9146923344156279\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=5,stop_words=\"english\")\n",
    "vect = tfidf.fit(X_train)\n",
    "X_train_tfidf = vect.transform(X_train)   \n",
    "print(\"Shape of X_train after transformation is {}\".format(X_train_tfidf.shape))\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train_tfidf,y_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "predictions = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "score_f1 = f1_score(y_test,predictions,average=\"binary\")\n",
    "score_roc_auc = roc_auc_score(y_test,predictions)\n",
    "\n",
    "print(\"Score from f1 score {}\".format(score_f1))\n",
    "print(\"Score from roc_auc {}\".format(score_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small coef words \n",
      " ['worst' 'waste' 'disappointed' 'useless' 'return' 'terrible' 'poor'\n",
      " 'horrible' 'worthless' 'returning']\n",
      "Large coef words \n",
      " ['best' 'easy' 'far' 'perfectly' 'awesome' 'loves' 'amazing' 'perfect'\n",
      " 'excellent' 'great']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = log_reg.coef_[0].argsort()    # it is sorting as per arguments, so 0 i.e. negative reviews will come first n\n",
    "                                                   # then positive review words\n",
    "\n",
    "print(\"Small coef words or Negative review words \\n {}\".format(feature_names[sorted_coef_index[:10]]))\n",
    "print(\"Large coef words or Positive review words \\n {}\".format(feature_names[sorted_coef_index[-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# an issue with the count_vectorizer and tfidf_vectorizer is that it doesnt maintain the order. This means that any word\n",
    "# appearing in the beginning or end will be considered as same for eg:\n",
    "\n",
    "print(log_reg.predict(tfidf.transform([\"not an issue,phone is working\", \"an issue, phone is not working fine \"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that in first sentence, it was a positive word, but due to non-maintainence of order, the model considered it as negative\n",
    "\n",
    "Solution : We can use n_grams model for this. Right now, we are using bag of words model, which is n_gram model with n=1. If we use n=2, the model will not choose single words, but will use 2 words together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train after transformation is (231207, 284382)\n",
      "Score from f1 score 0.9711319583362076\n",
      "Score from roc_auc 0.9354505150919952\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,3),stop_words=\"english\",min_df=5)\n",
    "vect = tfidf.fit(X_train)\n",
    "X_train_tfidf = vect.transform(X_train)\n",
    "print(\"Shape of X_train after transformation is {}\".format(X_train_tfidf.shape))\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train_tfidf,y_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "predictions = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "score_f1 = f1_score(y_test,predictions,average=\"binary\")\n",
    "score_roc_auc = roc_auc_score(y_test,predictions)\n",
    "\n",
    "print(\"Score from f1 score {}\".format(score_f1))\n",
    "print(\"Score from roc_auc {}\".format(score_roc_auc))\n",
    "\n",
    "# we can see that now our vector size has increased to 284382\n",
    "\n",
    "# hr@tidyquant.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small coef words or Negative review words \n",
      " ['awful phone phone' 'able activated recommend' 'black screen screen'\n",
      " 'bean easily updated' 'ago sent' 'assignment mismatch location'\n",
      " 'batter power waiting' 'better issues phone' 'awhile make leap'\n",
      " 'awkward calling contact']\n",
      "Large coef words or Positive review words \n",
      " ['2016 lines' 'apps gmail instagram' 'accents aluminum' '20 35 mins'\n",
      " '13 16 wow' 'acquire warranty situation' 'android phones wanted'\n",
      " 'apps easily phone' 'accidentally dropping pantechs' 'android market pros']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = log_reg.coef_[0].argsort()\n",
    "\n",
    "\n",
    "print(\"Small coef words or Negative review words \\n {}\".format(feature_names[sorted_coef_index[:10]]))\n",
    "print(\"Large coef words or Positive review words \\n {}\".format(feature_names[sorted_coef_index[-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.predict(tfidf.transform([\"not an issue,phone is working\", \"an issue, phone is not working fine \"])))\n",
    "\n",
    "# now, we can see that it has correctly detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# clf = Pipeline([(\"vect\",CountVectorizer()),(\"tfidf\" , TfidfTransformer()),(\"\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
